{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bd9261",
   "metadata": {},
   "source": [
    "# Step 1. Open the data file and read the general information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83706a54",
   "metadata": {},
   "source": [
    "## Project description\n",
    "For a mobile carrier, Megaline, we want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. We need to develop a model that will pick the right plan. We will try to develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. We will check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65117ccd",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f22b2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53750a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "889cd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('users_behavior.csv')\n",
    "except:\n",
    "    df = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d469af",
   "metadata": {},
   "source": [
    "## Step 2. Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab27ca0",
   "metadata": {},
   "source": [
    "- сalls — number of calls,\n",
    "- minutes — total call duration in minutes,\n",
    "- messages — number of text messages,\n",
    "- mb_used — Internet traffic used in MB,\n",
    "- is_ultra — plan for the current month (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "67cd14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a78be",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "909aa74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>50.0</td>\n",
       "      <td>359.73</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3664.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>30.0</td>\n",
       "      <td>225.11</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12280.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>107.0</td>\n",
       "      <td>733.45</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10756.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>66.0</td>\n",
       "      <td>479.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11500.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>15.0</td>\n",
       "      <td>84.66</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4353.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "1399   50.0   359.73     102.0   3664.60         1\n",
       "2454   30.0   225.11      30.0  12280.81         0\n",
       "2806  107.0   733.45      98.0  10756.78         1\n",
       "2553   66.0   479.26      20.0  11500.33         0\n",
       "2209   15.0    84.66      13.0   4353.73         1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e45140b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "149d6041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3444abb",
   "metadata": {},
   "source": [
    "More then double amount of Smart then Ultra plan. We should remember to see that the split for validation keeps the same proportion and not worse. We will create a function to calculate this proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8dc8139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_of_ultra(df):\n",
    "    value_count = df['is_ultra'].value_counts()\n",
    "    proportion = df['is_ultra'].value_counts()[1]/(\n",
    "        df['is_ultra'].value_counts()[1]+df['is_ultra'].value_counts()[0])\n",
    "    return round(proportion, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794bdb0",
   "metadata": {},
   "source": [
    "# Split the source data into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "65b5ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid_and_test = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "df_valid, df_test = train_test_split(df_valid_and_test, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecbc77",
   "metadata": {},
   "source": [
    "See if the proportion of ultra plan stay the same after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "93b044d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train proportion: 0.31\n",
      "df_valid proportion: 0.29\n",
      "df_test proportion: 0.32\n"
     ]
    }
   ],
   "source": [
    "print('df_train proportion:', proportion_of_ultra(df_train))\n",
    "print('df_valid proportion:', proportion_of_ultra(df_valid))\n",
    "print('df_test proportion:', proportion_of_ultra(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c2896",
   "metadata": {},
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d93a63",
   "metadata": {},
   "source": [
    "# Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccac1f4",
   "metadata": {},
   "source": [
    "Because our task is to recommend between plans then any wrong recommendation will be considered as error. Whether we decide to recommend for Ultra when the target for this observation was Smart or the opposite. Therefore we will evaluate the model with accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c731671",
   "metadata": {},
   "source": [
    "This is a classification task so we will check which learning algorithm for classification yields the best accuracy. The models we will check are: Decision tree, Random forest and Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558886eb",
   "metadata": {},
   "source": [
    "create features and target for the models check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "281af6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5205e08",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e0b5b",
   "metadata": {},
   "source": [
    "loop tree depth to optimize the model depth with best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e2887f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7542768273716952\n",
      "max_depth = 2 : 0.7822706065318819\n",
      "max_depth = 3 : 0.7853810264385692\n",
      "max_depth = 4 : 0.7791601866251944\n",
      "max_depth = 5 : 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth) # create a model with the given depth\n",
    "    model.fit(features_train, target_train) # train the model\n",
    "    predictions_valid = model.predict(features_valid) # get the model's predictions\n",
    "    result = accuracy_score(target_valid, predictions_valid) # calculate the accuracy\n",
    "    print(\"max_depth =\", depth, \": \", end='')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a283e",
   "metadata": {},
   "source": [
    "Depth 3 give the highest accuracy - 0.785"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f49cc1",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae46c6b",
   "metadata": {},
   "source": [
    "loop tree number of trees to optimize the model with best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9907c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the validation set (n_estimators = 8): 0.7822706065318819\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 10): # choose hyperparameter range\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est) # set number of trees\n",
    "    model.fit(features_train, target_train) # train model on training set\n",
    "    score = model.score(features_valid, target_valid) # calculate accuracy score on validation set\n",
    "    if score > best_score:\n",
    "        best_score = score# save best accuracy score on validation set\n",
    "        best_est = est# save number of estimators corresponding to best accuracy score\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0181e03",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee421fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the validation set is: 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='lbfgs')\n",
    "model.fit(features_train, target_train) \n",
    "score = model.score(features_valid, target_valid) \n",
    "print('The accuracy of the validation set is:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a14943",
   "metadata": {},
   "source": [
    "## Model study conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d933f29",
   "metadata": {},
   "source": [
    "The highest accuracy we got is 0.785 and the model that allowed it is decision tree with depth of 3. Other models with different hyperparameters couldn't compete that. Therefore we select this model with and will check the quality of this model with the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189d92e",
   "metadata": {},
   "source": [
    "# Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "86ce9b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is: 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth=3)\n",
    "model.fit(features_train, target_train) # fit with train data\n",
    "predictions_test = model.predict(features_test) # predict with test data\n",
    "result = accuracy_score(target_test, predictions_test)\n",
    "print('The accuracy of the test set is:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd39386",
   "metadata": {},
   "source": [
    "The accuracy is a bit lower but very close to what achieved in the validation of the model. We can say that the model is not overfitted and also we can't say it's underfitted because it's still a high accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
